{"cells":[{"cell_type":"markdown","metadata":{"id":"lqt_yzRy16Wj"},"source":["## Compulsory Task \n","\n","In this compulsory task you will clean the country column and parse the date column in the **store_income_data_task.csv** file."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"vBP3WN2O16Wp"},"outputs":[],"source":["# Load up store_income_data.csv"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\kirst\\anaconda3\\Lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n","  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"]}],"source":["# Import libraries\n","import pandas as pd\n","import fuzzywuzzy \n","from fuzzywuzzy import process, fuzz\n","import chardet \n","from datetime import datetime\n","\n","# Load the dataset\n","income_df = pd.read_csv('store_income_data_task.csv')"]},{"cell_type":"markdown","metadata":{"id":"ItqLwumA16Wr"},"source":["1. Take a look at all the unique values in the \"country\" column. Then, convert the column to lowercase and remove any trailing white spaces."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"sLkzt4Hr16Wr"},"outputs":[{"name":"stdout","output_type":"stream","text":["Unique values before cleaning: ['United States/' 'Britain' ' United States' 'Britain/' ' United Kingdom'\n"," 'U.K.' 'SA ' 'U.K/' 'America' 'United Kingdom' nan 'united states'\n"," ' S.A.' 'England ' 'UK' 'S.A./' 'ENGLAND' 'BRITAIN' 'U.K' 'U.K '\n"," 'America/' 'SA.' 'S.A. ' 'u.k' 'uk' ' ' 'UK.' 'England/' 'england'\n"," ' Britain' 'united states of america' 'UK/' 'SA/' 'SA' 'England.'\n"," 'UNITED KINGDOM' 'America.' 'S.A..' 's.a.' ' U.K'\n"," ' United States of America' 'Britain ' 'England' ' SA'\n"," 'United States of America.' 'United States of America/' 'United States.'\n"," 's. africasouth africa' ' England' 'United Kingdom '\n"," 'United States of America ' ' UK' 'united kingdom' 'AMERICA' 'America '\n"," 'UNITED STATES OF AMERICA' ' S. AfricaSouth Africa' 'america'\n"," 'S. AFRICASOUTH AFRICA' 'Britain.' '/' 'United Kingdom.' 'United States'\n"," ' America' 'UNITED STATES' 'sa' 'United States of America' 'UK '\n"," 'United States ' 'S. AfricaSouth Africa/' 'S.A.' 'United Kingdom/'\n"," 'S. AfricaSouth Africa ' 'S. AfricaSouth Africa.' 'S. AfricaSouth Africa'\n"," '.' 'britain']\n"]}],"source":["# Inspect unique values in the \"country\" column\n","unique_countries = income_df['country'].unique()\n","print(\"Unique values before cleaning:\", unique_countries)\n","\n","# Convert \"country\" column to lowercase and strip trailing whitespace\n","income_df['country'] = income_df['country'].str.lower().str.strip()"]},{"cell_type":"markdown","metadata":{"id":"P6dcDc4P16Ws"},"source":["2. Note that there should only be three separate countries. Eliminate all variations, so that 'South Africa', 'United Kingdom' and 'United States' are the only three countries."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"qeV3CxMR16Ws"},"outputs":[{"name":"stdout","output_type":"stream","text":["Unique values after cleaning: ['United States' 'United Kingdom' 'South Africa' 'Unknown']\n"]}],"source":["\n","# Manually map obvious matches\n","manual_mapping = {\n","    'uk': 'united kingdom',\n","    'u.k': 'united kingdom',\n","    'u.k.': 'united kingdom',\n","    'u.k/': 'united kingdom',\n","    'england': 'united kingdom',\n","    'england.': 'united kingdom',\n","    'england/': 'united kingdom',\n","    'britain': 'united kingdom',\n","    'britain.': 'united kingdom',\n","    'britain/': 'united kingdom',\n","    'america': 'united states',\n","    'america.': 'united states',\n","    'america/': 'united states',\n","    'united states of america': 'united states',\n","    'united states of america.': 'united states',\n","    'united states of america/': 'united states',\n","    'sa': 'south africa',\n","    's.a.': 'south africa',\n","    's.a./': 'south africa',\n","    's.a..': 'south africa',\n","    's. africasouth africa': 'south africa',\n","    's. africasouth africa/': 'south africa',\n","    's. africasouth africa.': 'south africa',\n","    'uk.': 'united kingdom',\n","    'uk/': 'united kingdom',\n","    'sa.': 'south africa',\n","    'sa/': 'south africa',\n","    '.': 'unknown',\n","    '/': 'unknown',\n","    '': 'unknown'\n","}\n","\n","# Apply manual mapping\n","income_df['country'] = income_df['country'].replace(manual_mapping)\n","\n","# Function to replace rows in the provided column of the \n","# provided DataFrame\n","# that match the provided string above the provided ratio with \n","# the provided string\n","def replace_matches_in_column(df, column, string_to_match, min_ratio=90):\n","    # Get a list of unique strings\n","    strings = df[column].unique()\n","    \n","    # Get the closest matches to our input string\n","    matches = process.extract(string_to_match, strings, \n","                              limit=len(strings), scorer=fuzz.token_sort_ratio)\n","\n","    # Only get matches with a ratio above the min_ratio\n","    close_matches = [match[0] for match in matches if match[1] >= min_ratio]\n","\n","    # Get the rows of all the close matches in the DataFrame\n","    rows_with_matches = df[column].isin(close_matches)\n","\n","    # Replace all rows with close matches with the input string\n","    df.loc[rows_with_matches, column] = string_to_match\n","\n","# Apply fuzzy matching to standardize country names\n","for standard_country in ['united kingdom', 'united states', 'south africa']:\n","    replace_matches_in_column(income_df, 'country', standard_country)\n","\n","# Handle remaining NaN or empty string values\n","income_df['country'] = income_df['country'].fillna('unknown')\n","income_df['country'] = income_df['country'].str.title()\n","\n","# Check the final unique values\n","cleaned_unique_countries = income_df['country'].unique()\n","print(f\"Unique values after cleaning: {cleaned_unique_countries}\")\n","\n","# Save the cleaned data (optional)\n","income_df.to_csv('cleaned_data.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"UJZDMTwP16Ws"},"source":["3. Create a new column called `days_ago` in the DataFrame that is a copy of the 'date_measured' column but instead it is a number that shows how many days ago it was measured from the current date. Note that the current date can be obtained using `datetime.date.today()`."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"gMJbN84P16Wt"},"outputs":[{"name":"stdout","output_type":"stream","text":["  date_measured  days_ago\n","0    2006-02-04      6762\n","1    2006-01-04      6793\n","2    2003-09-12      7638\n","3    2006-05-08      6669\n","4    1973-01-21     18829\n"]}],"source":["# Convert 'date_measured' column to datetime format\n","income_df['date_measured'] = pd.to_datetime(income_df['date_measured'],\n","                                            format='%d-%m-%Y', errors='coerce')\n","\n","# Get the current date\n","current_date = datetime.today()\n","\n","# Calculate the number of days ago for each date and add it as a new column\n","income_df['days_ago'] = (current_date - income_df['date_measured']).dt.days\n","\n","# Inspect the DataFrame to see the new 'days_ago' column\n","print(income_df[['date_measured', 'days_ago']].head())"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.10.0 ('phd')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"},"vscode":{"interpreter":{"hash":"63d17dc58a06b6a6d4136fb13c245dafcf53668da37b1c3052c24d689135f5bb"}}},"nbformat":4,"nbformat_minor":0}
